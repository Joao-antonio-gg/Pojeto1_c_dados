{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: \n",
    "\n",
    "Nome: \n",
    "\n",
    "    Nome: Mateus Ruggero SUAVIZA√á√ÉO DE LAPLACE N√ÉO ESQUECE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\joaop\\Desktop\\insper 2\\ciencia dos dados\\Projeto_1\\Pojeto1_c_dados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Shang Chi.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maldito capitalismo que n√£o me deixa ir ver sh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üí≠üí≠ shang chi usando fones de ouvido üí≠üí≠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>queria assistir shang chi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uma blusinha de shang chi pf renner riachuelo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indo assistir shang chi sozinha espero que ngn...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  maldito capitalismo que n√£o me deixa ir ver sh...           3\n",
       "1             üí≠üí≠ shang chi usando fones de ouvido üí≠üí≠           0\n",
       "2                          queria assistir shang chi           3\n",
       "3  uma blusinha de shang chi pf renner riachuelo ...           1\n",
       "4  indo assistir shang chi sozinha espero que ngn...           3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esperando um drive de shang chi decente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t√¥ falando: v√£o ver shang chi ü§© https://t.co/u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assisti shang - chi e pra mim √© o melhor filme...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sabe quando vc quer fazer uma coisa q sabe q e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n tem uma m√≠sera alma pra ir ver shang chi com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0            esperando um drive de shang chi decente           1\n",
       "1  t√¥ falando: v√£o ver shang chi ü§© https://t.co/u...           1\n",
       "2  assisti shang - chi e pra mim √© o melhor filme...           2\n",
       "3  sabe quando vc quer fazer uma coisa q sabe q e...           1\n",
       "4  n tem uma m√≠sera alma pra ir ver shang chi com...           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto escolhido foi o filme Shang-Chi e a lenda dos dez an√©is.\n",
    "Para avaliar como relevante, bastava o usuario ter visto o filme e mostrado interesse ou querer ver de novo, mas para ser muito relevante era preciso passar alguma cr√≠tica ao filme ou mostrar muito entusiasmo a respeito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Transformando o total das palavras em DataFrame##############################################################################\n",
    "\n",
    "total_raw = [] #Colocando frases em uma lista\n",
    "for i in range(0, len(train)):\n",
    "    total_raw.append(train['Treinamento'][i])\n",
    "\n",
    "frases_lower = [] #Colocando as frases em lower case\n",
    "for i in range(0, len(total_raw)):\n",
    "    frases_lower.append(cleanup(total_raw[i].lower()))\n",
    "\n",
    "total = [] #Transformando a lista em um √≠ndice para cada palavra\n",
    "for frase in frases_lower:\n",
    "    x = frase.split()\n",
    "    for i in range(0, len(x)):\n",
    "        total.append(x[i])\n",
    "\n",
    "#Data Frame\n",
    "total_serie = pd.Series(total)\n",
    "total_relativo = total_serie.value_counts(True)\n",
    "\n",
    "###Transformando os tweets irrelevantes em DataFrame############################################################################\n",
    "\n",
    "irr_raw = [] #Colocando em uma lista\n",
    "tweets_irrelevantes = train.loc[train['Relevancia'] == 0, :]\n",
    "\n",
    "tweets_irrelevantes\n",
    "for tweet in tweets_irrelevantes['Treinamento']:\n",
    "    irr_raw.append(tweet)\n",
    "\n",
    "irr_lower = [] #Colocando as frases em lower case\n",
    "for i in range(0, len(irr_raw)):\n",
    "    irr_lower.append(cleanup(irr_raw[i].lower()))\n",
    "\n",
    "irr = [] #Transformando a lista em um √≠ndice para cada palavra\n",
    "for frase in irr_lower:\n",
    "    x = frase.split()\n",
    "    for i in range(0, len(x)):\n",
    "        irr.append(x[i])\n",
    "\n",
    "#Data Frame\n",
    "irr_serie = pd.Series(irr)\n",
    "irr_relativo = irr_serie.value_counts(True)\n",
    "\n",
    "# ###Transformando os tweets relevantes em DataFrame############################################################################\n",
    "\n",
    "rel_raw = [] #Colocando em uma lista\n",
    "tweets_relevantes = train.loc[train['Relevancia'] == 1, :]\n",
    "\n",
    "for tweet in tweets_relevantes['Treinamento']:\n",
    "    rel_raw.append(tweet)\n",
    "\n",
    "rel_lower = [] #Colocando as frases em lower case\n",
    "for i in range(0, len(rel_raw)):\n",
    "    rel_lower.append(cleanup(rel_raw[i].lower()))\n",
    "\n",
    "rel = [] #Transformando a lista em um √≠ndice para cada palavra\n",
    "for frase in rel_lower:\n",
    "    x = frase.split()\n",
    "    for i in range(0, len(x)):\n",
    "        rel.append(x[i])\n",
    "\n",
    "#Data Frame\n",
    "rel_serie = pd.Series(rel)\n",
    "rel_relativo = rel_serie.value_counts(True)\n",
    "\n",
    "###Transformando os tweets muito relevantes em DataFrame########################################################################\n",
    "\n",
    "mt_rel_raw = [] #Colocando em uma lista\n",
    "tweets_muito_relevantes = train.loc[train['Relevancia'] == 2, :]\n",
    "\n",
    "for tweet in tweets_muito_relevantes['Treinamento']:\n",
    "    mt_rel_raw.append(tweet)\n",
    "\n",
    "mt_rel_lower = [] #Colocando as frases em lower case\n",
    "for i in range(0, len(mt_rel_raw)):\n",
    "    mt_rel_lower.append(cleanup(mt_rel_raw[i].lower()))\n",
    "\n",
    "mt_rel = [] #Transformando a lista em um √≠ndice para cada palavra\n",
    "for frase in mt_rel_lower:\n",
    "    x = frase.split()\n",
    "    for i in range(0, len(x)):\n",
    "        mt_rel.append(x[i])\n",
    "\n",
    "#Data Frame\n",
    "mt_rel_serie = pd.Series(mt_rel)\n",
    "mt_rel_relativo = mt_rel_serie.value_counts(True)\n",
    "\n",
    "###Transformando os tweets muito relevantes em DataFrame########################################################################\n",
    "\n",
    "int_raw = [] #Colocando em uma lista\n",
    "tweets_int = train.loc[train['Relevancia'] == 3, :]\n",
    "\n",
    "for tweet in tweets_int['Treinamento']:\n",
    "    int_raw.append(tweet)\n",
    "\n",
    "int_lower = [] #Colocando as frases em lower case\n",
    "for i in range(0, len(int_raw)):\n",
    "    int_lower.append(cleanup(int_raw[i].lower()))\n",
    "\n",
    "int_ver = [] #Transformando a lista em um √≠ndice para cada palavra\n",
    "for frase in int_lower:\n",
    "    x = frase.split()\n",
    "    for i in range(0, len(x)):\n",
    "        int_ver.append(x[i])\n",
    "\n",
    "#Data Frame\n",
    "int_serie = pd.Series(mt_rel)\n",
    "int_relativo = int_serie.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###C√°lculo de P(I), P(R) e P(MR)################################################################################################\n",
    "\n",
    "probI = len(irr_serie)/len(total_serie)\n",
    "probR = len(rel_serie)/len(total_serie)\n",
    "probMR = len(mt_rel_serie)/len(total_serie)\n",
    "probIV = len(int_serie)/len(total_serie)\n",
    "\n",
    "###C√°lculo da probabilidade#####################################################################################################\n",
    "\n",
    "def Prob(tweet):\n",
    "    twt = cleanup(tweet.lower()) #Limpar o tweet\n",
    "    tweet_certo = twt.split()\n",
    "    \n",
    "    ProbTweetDadoI = 1\n",
    "    ProbTweetDadoR = 1\n",
    "    ProbTweetDadoMR = 1\n",
    "    ProbTweetDadoIV = 1\n",
    "    \n",
    "  #C√°lculo de P(tweet|I), P(tweet|R) e P(tweet|MR)##############################################################################\n",
    "    \n",
    "    for palavra in tweet_certo:\n",
    "        \n",
    "        if palavra in irr_serie.value_counts():\n",
    "            cont_palavra_irr = irr_serie.value_counts()[palavra]\n",
    "        else:\n",
    "            cont_palavra_irr = 0\n",
    "            \n",
    "        if palavra in rel_serie.value_counts():\n",
    "            cont_palavra_rel = rel_serie.value_counts()[palavra]\n",
    "        else:\n",
    "            cont_palavra_rel = 0\n",
    "            \n",
    "        if palavra in mt_rel_serie.value_counts():\n",
    "            cont_palavra_mt_rel = mt_rel_serie.value_counts()[palavra]\n",
    "        else:\n",
    "            cont_palavra_mt_rel = 0\n",
    "            \n",
    "        if palavra in int_serie.value_counts():\n",
    "            cont_palavra_int = int_serie.value_counts()[palavra]\n",
    "        else:\n",
    "            cont_palavra_int = 0\n",
    "    \n",
    "        ProbTweetDadoI = ProbTweetDadoI * ((cont_palavra_irr + 1)/(len(irr_serie) + len(total_relativo)))\n",
    "        ProbTweetDadoR = ProbTweetDadoR * ((cont_palavra_rel + 1)/(len(rel_serie) + len(total_relativo)))\n",
    "        ProbTweetDadoMR = ProbTweetDadoMR * ((cont_palavra_mt_rel + 1)/(len(mt_rel_serie) + len(total_relativo)))\n",
    "        ProbTweetDadoIV = ProbTweetDadoIV * ((cont_palavra_int + 1)/(len(int_serie) + len(total_relativo)))\n",
    "\n",
    "  #C√°lculo de P(I|tweet), P(R|tweet) e P(MR|tweet)##############################################################################\n",
    "    P_I_tweet = ProbTweetDadoI * probI\n",
    "    P_R_tweet = ProbTweetDadoR * probR\n",
    "    P_MR_tweet = ProbTweetDadoMR * probMR\n",
    "    P_I_V_tweet = ProbTweetDadoIV * probIV\n",
    "    \n",
    "    lista = [P_I_tweet,P_R_tweet,P_MR_tweet,]\n",
    "    \n",
    "    if P_I_tweet == max(lista):\n",
    "        return 0\n",
    "    elif P_R_tweet == max(lista):\n",
    "        return 1\n",
    "    elif P_MR_tweet == max(lista):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "lista_relevancia = []\n",
    "for tweet in test['Teste']:\n",
    "    y = Prob(tweet)\n",
    "    lista_relevancia.append(y)\n",
    "    i += 1\n",
    "    \n",
    "lista_relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.109091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.038961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0              0         1         2\n",
       "Relevancia                              \n",
       "0           0.327273  0.563636  0.109091\n",
       "1           0.077922  0.883117  0.038961\n",
       "2           0.161290  0.161290  0.677419\n",
       "3           0.027027  0.972973  0.000000\n",
       "All         0.150000  0.700000  0.150000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array(lista_relevancia)\n",
    "pd.crosstab(test['Relevancia'], array, margins = True, normalize = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    186\n",
       "3    133\n",
       "0    127\n",
       "2    104\n",
       "Name: Relevancia, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Relevancia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    77\n",
       "0    55\n",
       "3    37\n",
       "2    31\n",
       "Name: Relevancia, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Relevancia'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.357142857142854\n",
      "69.64285714285714\n",
      "85.91549295774648\n",
      "14.084507042253522\n",
      "60.60606060606061\n",
      "39.39393939393939\n",
      "0\n",
      "100\n",
      "49.0\n"
     ]
    }
   ],
   "source": [
    "II = 17/56 * 100\n",
    "IO = (56-17)/56 * 100\n",
    "RR = 61/71 * 100\n",
    "RO =(71-61)/71 * 100\n",
    "MRMR = 20/33 * 100\n",
    "MRO = (33-20)/33 * 100\n",
    "IVIV = 0\n",
    "IVO = 100\n",
    "CC = (17+61+20)/200 * 100\n",
    "print(II)\n",
    "print(IO)\n",
    "print(RR)\n",
    "print(RO)\n",
    "print(MRMR)\n",
    "print(MRO)\n",
    "print(IVIV)\n",
    "print(IVO)\n",
    "print(CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
